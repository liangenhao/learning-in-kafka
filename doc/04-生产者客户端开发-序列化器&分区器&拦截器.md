---
title: 04-生产者客户端开发-序列化器&分区器&拦截器
date: 2019-08-03
categories: learning-in-kafka
tags: [Kafka]
---

> 消息在通过`send()`方法发往 broker 的过程中，需要经过拦截器、序列化器、分区器的一系列作用。
>
> - 拦截器是非必需的。
>
> - 序列化器是必需的。
>
> - 若`ProducerRecord`中指定了分区，则分区器不是必需的，如果未指定，则是必需的。

## 序列化器

【为什么需要序列化器】：由于 broker 接受的消息必须以**字节数组**的形式存在。因此，生产者需要用序列化器把对象转换成字节数组才能通过网络发送给 kafka。

> 因此，在对侧，消费者，需要使用<u>反序列化器</u>把从kafka中收到的字节数组转换成相应的对象。
>
> 详见：TODO。

【序列化器的作用】：将对象转换成字节数组(`byte[]`)。

【常见的序列化器】：

- `ByteArraySerializer`、`ByteBufferSerializer`、`BytesSerializer`
- `DoubleSerializer`、`FloatSerializer`、`IntegerSerializer`、`LongSerializer`、`ShortSerializer`、`StringSerializer`

### Serializer接口

`org.apache.kafka.common.serialization.Serializer`是序列化器实现类的父接口。

```java
public interface Serializer<T> extends Closeable {

    void configure(Map<String, ?> configs, boolean isKey);

    byte[] serialize(String topic, T data);

    @Override
    void close();
}
```

- `configure()`：

  - 【作用】：方法用来配置当前类。

    > 例如`StringSerializer`，用来确定编码类型。其他的一般为空方法。

  - 【调用时机】：创建`KafkaProducer`实例的时候调用。

- `serialize()`：

  - 【作用】：执行序列化操作。将相应的类型转换为`byte[]`。
  - 【调用时机】：发送消息时：`KafkaProducer#doSend`；

- `close()`：

  - 【作用】：关闭当前的序列化器。
  - 【注意】：**通常是个空方法**，如果实现此方法，需要确保此方法的**幂等性**。因为该方法会被`KafkaProducer`多次调用。
  - 【调用时机】：`KafkaProducer#close`

### 自定义序列化器

步骤：

1. 自定义序列化器，实现`Serializer`接口。
2. 配置生产者客户端参数：`key.serializer` & `value.serializer`。

> 详见`com.enhao.learning.in.kafka.sample.producer_client.serializer`。

## 分区器

【分区器的作用】：确定消息发往的分区，**为消息分配分区。**

- 如果消息`ProducerRecord`中指定了`partition`，那么不需要依赖分区器。
- 如果消息`ProducerRecord`中没有指定`partition`，那么需要依赖分区器。

【默认分区器】：`org.apache.kafka.clients.producer.internals.DefaultPartitioner`。

### Partitioner接口

```java
public interface Partitioner extends Configurable, Closeable {

    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);

    public void close();

}
```

- `partition()`：

  - 【作用】：计算分区号。

  - 【调用时机】：`KafkaProducer#doSend`。

    > `doSend()`方法中，调用了key&value的序列化器之后，调用分区器。

- `close()`：

  - 【作用】：关闭分区器的时候用来回收一些资源。
  - 【调用时机】：`KafkaProducer#close`。

- 父接口`Configurable`的方法`configure()`：

  - 【作用】：获取配置信息及初始化数据。
  - 【调用时机】：创建`KafkaProducer`实例的时候调用。

### DefaultPartitioner-默认分区器

> `org.apache.kafka.clients.producer.internals.DefaultPartitioner`。

`DefaultPartitioner`的`configure()`方法和`close()`方法都是空实现。

【分区逻辑】：

- 如果 key 不为null，那么默认的分区器会对 key 进行哈希（`MurmurHash2`算法），根据得到的哈希值来计算分区号。拥有相同 key 的消息会被写入同一个分区。

  > `MurmurHash2`算法具有高运算性能及低碰撞率。

- 如果 key 为null，那么消息将会以**轮询**的方式发往主题内的各个**可用分区**。

> 注意：key 不为null，计算得到的分区号是**<u>所有分区中的任意一个</u>**；key 为null并且有可用分区时，计算得到的分区号仅为**<u>可用分区中的任意一个</u>**。

```java
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    // 获取topic的所有分区
  	List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
    int numPartitions = partitions.size();
    if (keyBytes == null) {
      	// 获取下一个值，轮询方式
        int nextValue = nextValue(topic);
      	// 可用分区
        List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);
        if (availablePartitions.size() > 0) {
          	// 有可用分区，和可用分区数取余，得到分区号
            int part = Utils.toPositive(nextValue) % availablePartitions.size();
            return availablePartitions.get(part).partition();
        } else {
            // no partitions are available, give a non-available partition
          	// 没有可用分区，提供一个不可用的分区号
            return Utils.toPositive(nextValue) % numPartitions;
        }
    } else {
        // hash the keyBytes to choose a partition
      	// 使用MurmurHash2算法进行hash，然后和所有分区数取余来得到分区号
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }
}
```

### 自定义分区器

步骤：

1. 自定义分区器，实现`Partitioner`接口。
2. 配置生产者客户端参数：`partitioner.class`

> 详见：`com.enhao.learning.in.kafka.sample.producer_client.partitioner`。

## 生产者拦截器

【新功能】：从 kafka 0.10.0.0 开始。

【拦截器类型】：

- 生产者拦截器：详见本节。
- 消费者拦截器：详见[15-消费者客户端开发-消费者拦截器](15-消费者客户端开发-消费者拦截器.md)。

【作用】：

- 在消息发送前做些准备工作：`OnSend()`方法。

  > 比如按照某个规则过滤不符合要求的消息，修改消息的内容。

- 在发送回调逻辑前做一些定制化的需求：`onAcknowledgement()`方法。比如统计类的工作。

【拦截器链】：

- 通过配置生产者客户端参数`interceptor.classes`指定多个拦截器形成拦截器链。以逗号隔开。
- 拦截器顺序同配置的顺序。

### ProducerInterceptor接口

```java
public interface ProducerInterceptor<K, V> extends Configurable {
   
    public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);
  
    public void onAcknowledgement(RecordMetadata metadata, Exception exception);

    public void close();
}
```

> 在`KafkaProducer`中，拦截器是封装成了拦截器链对象`ProducerInterceptors`。方法也是通过拦截器链对象去调用。

- `onSend()`：

  - 【作用】：对消息进行相应的定制化操作。

  - 【调用时机】：`KafkaProducer#send(ProducerRecord<K,V>, Callback)`方法里调用。

    即在序列化和计算分区之前调用拦截器`onSend()`方法。

    > `onSend()`方法在`KafkaProducer#doSend`方法钱调用。

  - 【注意】：不要修改`ProducerRecord`的 topic、key 和 partition 等信息。

- `onAcknowledgement`：

  - 【作用】：拦截器应答。

  - 【调用时机】：

    在**消息被应答`Acknowledgement`之前**或**消息发送失败时**调用生产者拦截器的`onAcknowledgement()`方法，优先于用户设定的`Callback`之前执行。

  - 【注意】：该方法运行在 Producer 的I/O线程中。因此代码逻辑越简单越好。否则影响消息的发送速度。

- `close`：

  - 【作用】：关闭拦截器时执行一些资源的清理工作。
  - 【调用时机】：`KafkaProducer#close`。

- 父接口`Configurable`的方法`configure()`：

  - 【作用】：获取配置信息及初始化数据。
  - 【调用时机】：创建`KafkaProducer`实例的时候调用。

### 自定义生产者拦截器

步骤：

1. 自定义生产者拦截器，实现ProducerInterceptor接口。
2. 配置生产者客户端参数：`interceptor.classes`。

> 详见：`com.enhao.learning.in.kafka.sample.producer_client.producer_interceptor`



